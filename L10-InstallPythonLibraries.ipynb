{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Python Libraries for Lesson 10\n",
    "\n",
    "Here are some additional libraries you may not have installed previously.\n",
    "1. First verify the library is not pre-installed.\n",
    "2. Then install the library via pip within the container."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example with the `arrow` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'arrow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-59c3e9d7db5c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# try to import a library I knew would be missing to verify it's not pre-installed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0marrow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'arrow'"
     ]
    }
   ],
   "source": [
    "# try to import a library I knew would be missing to verify it's not pre-installed\n",
    "import arrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting arrow\n",
      "  Downloading arrow-0.15.7-py2.py3-none-any.whl (48 kB)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\zhuoy\\anaconda3\\lib\\site-packages (from arrow) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\zhuoy\\anaconda3\\lib\\site-packages (from python-dateutil->arrow) (1.14.0)\n",
      "Installing collected packages: arrow\n",
      "Successfully installed arrow-0.15.7\n"
     ]
    }
   ],
   "source": [
    "# use the bang ! syntax to install the library via pip within the container\n",
    "!pip install arrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arrow  # now the import succeeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple-lda (0.3.0)          - Python library for Latent Dirichlet allocation (lda)\n",
      "lda (1.1.0)                 - Topic modeling with latent Dirichlet allocation\n",
      "LDA-final-mz136 (1.5)       - Latent Dirichlet Allocation\n",
      "LDA-project-19 (1.5)        - Latent Dirichlet Allocation\n",
      "LDA-final-project-19 (1.5)  - Latent Dirichlet Allocation\n",
      "qlda (0.1.8)                - Lda-MLOPE\n",
      "tmlib (0.2.2)               - This is a LDA Package\n",
      "hdp (0.3)                   - Implementation of Hierarchical LDA\n",
      "hpd (0.3)                   - Implementation of Hierarchical LDA\n",
      "hplda (0.3)                 - Implementation of Hierarchical LDA\n",
      "hdproc (0.38)               - Implementation of Hierarchical LDA\n",
      "xbob.example.lda (1.0.3)    - (Fisher) Iris Flower LDA example\n",
      "pti-analyzer (0.0.19)       - Analyzing articles based on topic model(LDA)\n",
      "rlda (0.61)                 - A module to use robust lda topics for the study of text\n",
      "gaussianlda (0.2.9)         - Implementation of Gaussian LDA topic model, with efficiency tricks\n",
      "robics (0.11)               - Automatic detection of robust parametrizations for LDA and NMF. Compatible with scikit-learn and gensim.\n",
      "nlg-yongzhuo (0.0.4)        - text-summarization of extractive, include text_pronouns, text_teaser, mmr, text_rank, lead3, lda, lsi, nmf\n",
      "easyLDA (0.2.8.6)           - easily bult LDA Topic Models with just a list of docs (e.g. a list of twitter posts in CSV/TXT\n"
     ]
    }
   ],
   "source": [
    "!pip search lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lda'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-ff680a865002>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mlda\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'lda'"
     ]
    }
   ],
   "source": [
    "import lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lda\n",
      "  Downloading lda-1.1.0-cp37-cp37m-win_amd64.whl (341 kB)\n",
      "Collecting pbr<4,>=0.6\n",
      "  Downloading pbr-3.1.1-py2.py3-none-any.whl (99 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.13.0 in c:\\users\\zhuoy\\anaconda3\\lib\\site-packages (from lda) (1.18.1)\n",
      "Installing collected packages: pbr, lda\n",
      "Successfully installed lda-1.1.0 pbr-3.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## editdistance Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'editdistance'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-768acb15b586>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0meditdistance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'editdistance'"
     ]
    }
   ],
   "source": [
    "import editdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting editdistance\n",
      "  Downloading editdistance-0.5.3-cp37-cp37m-win_amd64.whl (23 kB)\n",
      "Installing collected packages: editdistance\n",
      "Successfully installed editdistance-0.5.3\n"
     ]
    }
   ],
   "source": [
    "!pip install editdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import editdistance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nltk Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rake-nltk (1.0.2)              - Python implementation of the Rapid Automatic Keyword Extraction algorithm using NLTK\n",
      "nltk (3.2.5)                   - Natural Language Toolkit\n",
      "  INSTALLED: 3.2.4\n",
      "  LATEST:    3.2.5\n",
      "nltkw (0.1.0)                  - NLTK wrapper\n",
      "nltkrest (0.12)                - NLTK as a REST service\n",
      "nltk_tgrep (1.0.6)             - tgrep2 Searching for NLTK Trees\n",
      "lektor-natural-language (0.1)  - Adds NLTK based template filters.\n",
      "bluestocking (0.1.2)           - An information extraction toolkit built on top of NLTK.\n",
      "luvina (0.0.26)                - High-level API for Natural Language Processing in NLTK\n",
      "wordgrapher (0.3.1)            - Word Graph utility built with NLTK and TextBlob\n",
      "metanl (0.5.6)                 - Multilingual natural language tools, wrapping NLTK and other systems.\n",
      "SloPOS (1.0)                   - Part of speech tagger for Slovenian (SI) language based on NLTK\n",
      "pysummarize (0.6.0)            - Simple multi-language Python and NLTK-based implementation of text summarization\n",
      "namebot (0.1.5)                - A company/product name generating tool written in Python.Uses NLTK and diverse wordplay techniques for sophisticated word generation and ideation\n"
     ]
    }
   ],
   "source": [
    "!pip search nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\zhuoy\\anaconda3\\lib\\site-packages (3.4.5)\n",
      "Requirement already satisfied: six in c:\\users\\zhuoy\\anaconda3\\lib\\site-packages (from nltk) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MessagePack\n",
    "It's like JSON. But fast and small.\n",
    "See <a href=\"https://msgpack.org/index.html\" title=\"MessagePack documentation\">msgpack.org</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: msgpack in c:\\users\\zhuoy\\anaconda3\\lib\\site-packages (0.6.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install msgpack --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gensim\n",
    "Gensim is a Python library for topic modeling, document indexing and similarity retrieval with large corpora. Target audience is the natural language processing (NLP) and information retrieval (IR) community.\n",
    "See https://pypi.org/project/gensim/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-e70e92d32c6e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gensim'"
     ]
    }
   ],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-3.8.3-cp37-cp37m-win_amd64.whl (24.2 MB)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-2.0.0.tar.gz (103 kB)\n",
      "Collecting Cython==0.29.14\n",
      "  Downloading Cython-0.29.14-cp37-cp37m-win_amd64.whl (1.7 MB)\n",
      "Requirement already satisfied: six>=1.5.0 in c:\\users\\zhuoy\\anaconda3\\lib\\site-packages (from gensim) (1.14.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\users\\zhuoy\\anaconda3\\lib\\site-packages (from gensim) (1.18.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\zhuoy\\anaconda3\\lib\\site-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied: requests in c:\\users\\zhuoy\\anaconda3\\lib\\site-packages (from smart-open>=1.8.1->gensim) (2.22.0)\n",
      "Requirement already satisfied: boto in c:\\users\\zhuoy\\anaconda3\\lib\\site-packages (from smart-open>=1.8.1->gensim) (2.49.0)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.14.7-py2.py3-none-any.whl (128 kB)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\zhuoy\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\zhuoy\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\zhuoy\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\zhuoy\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Collecting jmespath<1.0.0,>=0.7.1\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting s3transfer<0.4.0,>=0.3.0\n",
      "  Downloading s3transfer-0.3.3-py2.py3-none-any.whl (69 kB)\n",
      "Collecting botocore<1.18.0,>=1.17.7\n",
      "  Downloading botocore-1.17.7-py2.py3-none-any.whl (6.3 MB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\zhuoy\\anaconda3\\lib\\site-packages (from botocore<1.18.0,>=1.17.7->boto3->smart-open>=1.8.1->gensim) (2.8.1)\n",
      "Collecting docutils<0.16,>=0.10\n",
      "  Downloading docutils-0.15.2-py3-none-any.whl (547 kB)\n",
      "Building wheels for collected packages: smart-open\n",
      "  Building wheel for smart-open (setup.py): started\n",
      "  Building wheel for smart-open (setup.py): finished with status 'done'\n",
      "  Created wheel for smart-open: filename=smart_open-2.0.0-py3-none-any.whl size=101346 sha256=f1a8b860d58a11fc93fdc2567541d046785b78dd4ceb05d9573469232162905f\n",
      "  Stored in directory: c:\\users\\zhuoy\\appdata\\local\\pip\\cache\\wheels\\bb\\1c\\9c\\412ec03f6d5ac7d41f4b965bde3fc0d1bd201da5ba3e2636de\n",
      "Successfully built smart-open\n",
      "Installing collected packages: jmespath, docutils, botocore, s3transfer, boto3, smart-open, Cython, gensim\n",
      "  Attempting uninstall: docutils\n",
      "    Found existing installation: docutils 0.16\n",
      "    Uninstalling docutils-0.16:\n",
      "      Successfully uninstalled docutils-0.16\n",
      "  Attempting uninstall: Cython\n",
      "    Found existing installation: Cython 0.29.15\n",
      "    Uninstalling Cython-0.29.15:\n",
      "      Successfully uninstalled Cython-0.29.15\n",
      "Successfully installed Cython-0.29.14 boto3-1.14.7 botocore-1.17.7 docutils-0.15.2 gensim-3.8.3 jmespath-0.10.0 s3transfer-0.3.3 smart-open-2.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GloVe: Global Vectors for Word Representation\n",
    "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. <a href=\"https://nlp.stanford.edu/pubs/glove.pdf\" title=\"PDF for GloVe\">GloVe: Global Vectors for Word Representation</a>.\n",
    "\n",
    "You may encounter trouble installing this package because of Windows directory naming. See https://github.com/maciejkula/glove-python/issues/42 for more information and help installing. This package is not used in the Lesson 10 notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.6\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install glove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stopwords\n",
    "Stopwords filter for 42 languages\n",
    "See https://pypi.org/project/stopwords/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stopwords (0.1.3)                           - Stopwords filter for 42 languages\n",
      "stopwords-cnn (0.0.5)                       - Stopwords filter for Chinese\n",
      "stopwords-guilannlp (13.2019.3.5)           - A comprehensive package for stopwords in NLP and text mining\n",
      "stopword (0.0.4)                            - Stopwords filter for Chinese\n",
      "udicOpenData (2.4)                          - udic dictionary, stopwords module\n",
      "UdicToolKits (1.7)                          - udic dictionary, stopwords, TextPreprocessing module\n",
      "sngrams (0.2.0)                             - Term and paragraph frequency counts for non-stopwords in input document.\n",
      "text-hr (0.20)                              - Morphological/Inflection/Lemmatization Engine for Croatian language, POS tagger, stopwords\n",
      "stopwordsiso (0.5.1)                        - Collection of stopwords for multiple languages. Using ISO 639-1 language code.\n",
      "O-NLP-Preprocessor-Emeka-Onyebuchi (0.0.2)  - A python package that has various libraries for processing NLP text. While just specifying the pandas column, it automatically removes stopwords, tokenizes it, stems it and lemmatizes it\n"
     ]
    }
   ],
   "source": [
    "!pip search stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
